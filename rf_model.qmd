---
title: "Random Forest Model"
format:
  html:
    toc: true
    code-fold: true
---

```{r setup, include=FALSE}
source("setup.R")

library(tidyverse)
library(tidymodels)
theme_set(theme_minimal())

```


We trained a random forest model using the `ranger` engine in the `tidymodels` framework. This ensemble method aggregates multiple decision trees to improve prediction accuracy and reduce overfitting.

## Model Setup and Training
```{r}
#Random Forest Specification
rf_spec <- rand_forest(mtry = 4, trees = 500, min_n = 5) %>%
  set_engine("ranger", importance = "impurity") %>%
  set_mode("classification")

rf_wf <- workflow() %>%
  add_model(rf_spec) %>%
  add_recipe(heart_recipe)

#Fit Model
rf_fit <- fit(rf_wf, data = heart_train)

```
## Confusion Matrix

```{r}
rf_preds <- predict(rf_fit, heart_test, type = "prob") %>%
  bind_cols(predict(rf_fit, heart_test)) %>%
  bind_cols(heart_test)

rf_preds <- rf_preds %>%
  mutate(HeartDisease = factor(HeartDisease, levels = c(0, 1)))

rf_preds %>%
  conf_mat(truth = HeartDisease, estimate = .pred_class) %>%
  autoplot(type = "heatmap") +
  labs(title = "Confusion Matrix - Random Forest")

```
The random forest model shows strong classification performance:

- True Negatives (0 correctly predicted): 150

- True Positives (1 correctly predicted): 148

- False Positives: 10

- False Negatives: 0

This indicates excellent sensitivity (no false negatives) and high specificity, suggesting that the model accurately identifies both patients with and without heart disease, with minimal misclassification.

## ROC Curve

```{r}
rf_preds %>%
  roc_curve(truth = HeartDisease, .pred_1, event_level = "second") %>%
  autoplot() +
  labs(title = "ROC Curve - Random Forest") +
  theme_minimal()

```

The ROC curve for the random forest model climbs sharply to the top-left corner, indicating excellent discriminative ability. This shape suggests the model maintains a high true positive rate with minimal false positives across thresholds. The nearly perfect curve confirms that the random forest is highly effective at ranking heart disease risk and likely achieves an AUC close to 1.

## Train vs. Test Comparison

```{r}
# Generate predictions on training set
rf_preds_train <- predict(rf_fit, heart_train, type = "prob") %>%
  bind_cols(predict(rf_fit, heart_train)) %>%
  bind_cols(heart_train)

# Evaluate accuracy and AUC on training set
rf_train_metrics <- bind_rows(
  accuracy(rf_preds_train, truth = HeartDisease, estimate = .pred_class),
  roc_auc(rf_preds_train, truth = HeartDisease, .pred_1, event_level = "second")
)

rf_train_metrics

```

The random forest model achieved near-perfect performance on the training set, with an accuracy of 0.997 and an AUC of 1.000. This suggests that the model has learned the training data extremely well. However, such high scores raise concerns about potential overfitting, especially if the model's performance on the test set is significantly lower. Close monitoring of test results is necessary to ensure generalization and avoid overly optimistic training metrics.

##Global Feature Importance

```{r}
# Extract importance
rf_fit_raw <- extract_fit_parsnip(rf_fit)$fit
vip_rf <- as.data.frame(rf_fit_raw$variable.importance) %>%
  rownames_to_column("Feature") %>%
  rename(Importance = `rf_fit_raw$variable.importance`) %>%
  arrange(desc(Importance)) %>%
  slice_head(n = 5)

vip_rf

# Plot
vip_rf %>%
  ggplot(aes(x = fct_reorder(Feature, Importance), y = Importance)) +
  geom_col(fill = "darkgreen") +
  coord_flip() +
  labs(title = "Top 5 Feature Importances (Random Forest)", x = NULL, y = "Importance")

```
We observe that NumMajorVessels and Oldpeak are consistently ranked as top features, highlighting their predictive importance for heart disease. These will be compared with LIME explanations in later sections.

## Save for Comparison

```{r}
# Save top features for LIME comparison
rf_top_features <- vip_rf$Feature
saveRDS(rf_top_features, file = "scripts/rf_top_features.rds")

# Save fitted model for LIME explanation
saveRDS(rf_fit, file = "scripts/rf_fit.rds")
```

## Summary

This random forest model generally performs better than a single decision tree due to its ensemble nature.  
It will also be evaluated using LIME to understand its local predictions.