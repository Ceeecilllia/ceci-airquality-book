# Evaluating LIME Explanations on Heart Disease Prediction Models

In healthcare, it is critical to understand how models make predictions â€” especially when diagnosing heart disease. LIME (Local Interpretable Model-agnostic Explanations) offers human-friendly explanations even for complex models.

This project aims to evaluate the reliability of LIME explanations across different model types, including interpretable models such as decision trees and more complex models like neural networks.

We will answer the following research questions:
- Does LIME provide faithful explanations for interpretable models?
- How do LIME's feature rankings compare across different models?
- Can LIME be considered trustworthy for medical prediction tasks?
