[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Final project",
    "section": "",
    "text": "1 Evaluating LIME Explanations on Heart Disease Prediction Models\nIn healthcare, it is critical to understand how models make predictions — especially when diagnosing heart disease. LIME (Local Interpretable Model-agnostic Explanations) offers human-friendly explanations even for complex models.\nThis project aims to evaluate the reliability of LIME explanations across different model types, including interpretable models such as decision trees and more complex models like neural networks.\nWe will answer the following research questions: - Does LIME provide faithful explanations for interpretable models? - How do LIME’s feature rankings compare across different models? - Can LIME be considered trustworthy for medical prediction tasks?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Evaluating LIME Explanations on Heart Disease Prediction Models</span>"
    ]
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "2  Data",
    "section": "",
    "text": "3 Data\nIn this section, we provide an overview of the dataset used in our heart disease prediction task, along with key preprocessing and exploratory analysis steps.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#data-loading-and-preprocessing",
    "href": "data.html#data-loading-and-preprocessing",
    "title": "2  Data",
    "section": "5.1 Data Loading and Preprocessing",
    "text": "5.1 Data Loading and Preprocessing\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\n# Load the dataset\nheart &lt;- read_csv(\"data/heart.csv\")\n\n\nRows: 1025 Columns: 14\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (14): age, sex, cp, trestbps, chol, fbs, restecg, thalach, exang, oldpea...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\n# Rename variables for clarity\nheart &lt;- heart %&gt;%\n  rename(\n    Age = age,\n    Sex = sex,\n    ChestPainType = cp,\n    RestingBP = trestbps,\n    Cholesterol = chol,\n    FastingBS = fbs,\n    RestingECG = restecg,\n    MaxHR = thalach,\n    ExerciseAngina = exang,\n    Oldpeak = oldpeak,\n    Slope = slope,\n    NumMajorVessels = ca,\n    Thalassemia = thal,\n    HeartDisease = target\n  ) %&gt;%\n  mutate(\n    Sex = as.factor(Sex),\n    ChestPainType = as.factor(ChestPainType),\n    RestingECG = as.factor(RestingECG),\n    ExerciseAngina = as.factor(ExerciseAngina),\n    Thalassemia = as.factor(Thalassemia),\n    HeartDisease = as.factor(HeartDisease)\n  )",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#age-distribution-by-heart-disease-status",
    "href": "data.html#age-distribution-by-heart-disease-status",
    "title": "2  Data",
    "section": "6.1 Age Distribution by Heart Disease Status",
    "text": "6.1 Age Distribution by Heart Disease Status\n\n\nCode\n# Basic structure\nglimpse(heart)\n\n\nRows: 1,025\nColumns: 14\n$ Age             &lt;dbl&gt; 52, 53, 70, 61, 62, 58, 58, 55, 46, 54, 71, 43, 34, 51…\n$ Sex             &lt;fct&gt; 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, …\n$ ChestPainType   &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 2, 0, …\n$ RestingBP       &lt;dbl&gt; 125, 140, 145, 148, 138, 100, 114, 160, 120, 122, 112,…\n$ Cholesterol     &lt;dbl&gt; 212, 203, 174, 203, 294, 248, 318, 289, 249, 286, 149,…\n$ FastingBS       &lt;dbl&gt; 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, …\n$ RestingECG      &lt;fct&gt; 1, 0, 1, 1, 1, 0, 2, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, …\n$ MaxHR           &lt;dbl&gt; 168, 155, 125, 161, 106, 122, 140, 145, 144, 116, 125,…\n$ ExerciseAngina  &lt;fct&gt; 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, …\n$ Oldpeak         &lt;dbl&gt; 1.0, 3.1, 2.6, 0.0, 1.9, 1.0, 4.4, 0.8, 0.8, 3.2, 1.6,…\n$ Slope           &lt;dbl&gt; 2, 0, 0, 2, 1, 1, 0, 1, 2, 1, 1, 1, 2, 1, 1, 2, 2, 1, …\n$ NumMajorVessels &lt;dbl&gt; 2, 0, 0, 1, 3, 0, 3, 1, 0, 2, 0, 0, 0, 3, 0, 0, 1, 1, …\n$ Thalassemia     &lt;fct&gt; 3, 3, 3, 3, 2, 2, 1, 3, 3, 2, 2, 3, 2, 3, 0, 2, 2, 3, …\n$ HeartDisease    &lt;fct&gt; 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, …\n\n\nCode\n# Proportion of heart disease cases\nheart %&gt;%\n  count(HeartDisease) %&gt;%\n  mutate(prop = n / sum(n))\n\n\n# A tibble: 2 × 3\n  HeartDisease     n  prop\n  &lt;fct&gt;        &lt;int&gt; &lt;dbl&gt;\n1 0              499 0.487\n2 1              526 0.513\n\n\n\n\nCode\n# Distribution of Age\nggplot(heart, aes(x = Age, fill = HeartDisease)) +\n  geom_histogram(bins = 30, position = \"dodge\") +\n  labs(title = \"Age Distribution by Heart Disease Status\")\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Chest Pain Type vs Disease\nggplot(heart, aes(x = ChestPainType, fill = HeartDisease)) +\n  geom_bar(position = \"fill\") +\n  labs(title = \"Chest Pain Type and Heart Disease\", y = \"Proportion\")\n\n\n\n\n\n\n\n\n\nAs shown, patients with heart disease (label 1) tend to be older.\nThe highest heart disease rate occurs around ages 55 to 65.\nLikewise, chest pain types 1 and 2 are more common in patients with heart disease, suggesting these features could be predictive.\nThese patterns will guide our model-building decisions and feature interpretation strategies in the next sections.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "models.html",
    "href": "models.html",
    "title": "3  Models Overview",
    "section": "",
    "text": "4 Models Overview\nIn this section, we provide an overview of the models used to predict heart disease based on clinical features.\nWe trained and evaluated four different models, each representing a different level of complexity and interpretability:\n\n\n\n\n\n\n\n\n\n\nModel\nEngine\nType\nInterpretability\nNotes\n\n\n\n\nDecision Tree\nrpart\nInterpretable\nHigh\nBaseline tree model\n\n\nRandom Forest\nranger\nEnsemble\nMedium\nHandles interactions, more robust\n\n\nSVM\nkernlab\nKernel-based\nLow\nSensitive to scaling\n\n\nNeural Network\nnnet\nNonlinear\nLow\nCan model complex patterns\n\n\n\nEach model is evaluated using: - Accuracy - AUC (Area Under the ROC Curve) - Global feature importance (e.g., using vip or built-in model metrics) - LIME local explanations\n\n\n\n5 Modeling Workflow\nWe use the tidymodels framework for consistency and reproducibility across models:\n\nSplit data: 70% training / 30% test\nRecipe preprocessing: dummy encoding, normalization, etc.\n10-fold cross-validation for tuning (if applicable)\nEvaluation on test set\n\nEach model is analyzed in its own chapter:\n\nDecision Tree\nRandom Forest\nSVM\nNeural Network\n\n\nThis modular approach allows us to compare different modeling philosophies and investigate how interpretation methods like LIME behave across them.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Models Overview</span>"
    ]
  },
  {
    "objectID": "tree_model.html",
    "href": "tree_model.html",
    "title": "4  Decision Tree Model",
    "section": "",
    "text": "4.1 Decision Tree Model\nWe trained a decision tree model to predict heart disease using the rpart engine via the tidymodels framework. This model is inherently interpretable and serves as a baseline for comparison.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Decision Tree Model</span>"
    ]
  },
  {
    "objectID": "tree_model.html#decision-tree-model",
    "href": "tree_model.html#decision-tree-model",
    "title": "4  Decision Tree Model",
    "section": "",
    "text": "4.1.1 Data Split and Preprocessing\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\n# Load the dataset\nheart &lt;- read_csv(\"data/heart.csv\")\n\n\nRows: 1025 Columns: 14\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (14): age, sex, cp, trestbps, chol, fbs, restecg, thalach, exang, oldpea...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\n# Rename + factor conversion\nheart &lt;- heart %&gt;%\n  rename(\n    Age = age,\n    Sex = sex,\n    ChestPainType = cp,\n    RestingBP = trestbps,\n    Cholesterol = chol,\n    FastingBS = fbs,\n    RestingECG = restecg,\n    MaxHR = thalach,\n    ExerciseAngina = exang,\n    Oldpeak = oldpeak,\n    Slope = slope,\n    NumMajorVessels = ca,\n    Thalassemia = thal,\n    HeartDisease = target\n  ) %&gt;%\n  mutate(\n    Sex = as.factor(Sex),\n    ChestPainType = as.factor(ChestPainType),\n    RestingECG = as.factor(RestingECG),\n    ExerciseAngina = as.factor(ExerciseAngina),\n    Thalassemia = as.factor(Thalassemia),\n    HeartDisease = as.factor(HeartDisease)\n  )",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Decision Tree Model</span>"
    ]
  },
  {
    "objectID": "lime_analysis.html",
    "href": "lime_analysis.html",
    "title": "5  LIME Analysis",
    "section": "",
    "text": "6 LIME Analysis\nWe applied LIME (Local Interpretable Model-agnostic Explanations) to generate local explanations for each of the four models.\nThe explanations focus on identifying the top 5 features contributing to each model’s predictions.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>LIME Analysis</span>"
    ]
  },
  {
    "objectID": "lime_analysis.html#lime-parameters",
    "href": "lime_analysis.html#lime-parameters",
    "title": "5  LIME Analysis",
    "section": "6.1 LIME Parameters",
    "text": "6.1 LIME Parameters\n\nNumber of features: 5\nNumber of permutations: 5000",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>LIME Analysis</span>"
    ]
  },
  {
    "objectID": "lime_analysis.html#example-lime-explanation",
    "href": "lime_analysis.html#example-lime-explanation",
    "title": "5  LIME Analysis",
    "section": "6.2 Example LIME Explanation",
    "text": "6.2 Example LIME Explanation\n\nInsert example code and output here, e.g., for one test set observation:\n\n```r # Example: Apply LIME to Decision Tree model library(lime)\nexplainer_tree &lt;- lime(training_data, model_tree) explanation_tree &lt;- explain(test_data[1, ], explainer = explainer_tree, n_features = 5, n_permutations = 5000)\nplot_features(explanation_tree)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>LIME Analysis</span>"
    ]
  },
  {
    "objectID": "conclusion.html",
    "href": "conclusion.html",
    "title": "6  Conclusion",
    "section": "",
    "text": "6.1 Key Findings",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Conclusion</span>"
    ]
  },
  {
    "objectID": "conclusion.html#key-findings",
    "href": "conclusion.html#key-findings",
    "title": "6  Conclusion",
    "section": "",
    "text": "LIME explanations aligned more closely with simpler models like decision trees.\nFor more complex models (e.g., neural networks), the LIME feature rankings showed greater variability.\nSome features such as Age, ChestPainType, and Cholesterol were consistently important across models and explanations.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Conclusion</span>"
    ]
  },
  {
    "objectID": "conclusion.html#limitations",
    "href": "conclusion.html#limitations",
    "title": "6  Conclusion",
    "section": "6.2 Limitations",
    "text": "6.2 Limitations\n\nLIME explanations are local and may not reflect the global model behavior.\nThe comparison is limited to one dataset and a small sample of instances.\nModel hyperparameters and preprocessing choices could affect results.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Conclusion</span>"
    ]
  },
  {
    "objectID": "conclusion.html#future-directions",
    "href": "conclusion.html#future-directions",
    "title": "6  Conclusion",
    "section": "6.3 Future Directions",
    "text": "6.3 Future Directions\n\nExplore other interpretability methods such as SHAP or Anchor explanations.\nApply the same analysis to other medical prediction datasets.\nInvolve domain experts (e.g., clinicians) to assess explanation usefulness in real-world decision-making.\n\n\nThis project highlights both the potential and the caution needed when interpreting machine learning models, especially in healthcare.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Conclusion</span>"
    ]
  }
]