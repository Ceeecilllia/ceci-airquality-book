[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Final project",
    "section": "",
    "text": "0.1 Overview\nThis project explores interpretable machine learning methods to predict the likelihood of heart disease from patient clinical data.\nWe build and compare five models:\nOur primary goal is not only to achieve high predictive accuracy, but also to understand why a model makes certain predictions.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Heart Disease Prediction and Explanation</span>"
    ]
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "2  Data",
    "section": "",
    "text": "3 Data\nIn this section, we provide an overview of the dataset used in our heart disease prediction task, along with key preprocessing and exploratory analysis steps.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#data-loading-and-preprocessing",
    "href": "data.html#data-loading-and-preprocessing",
    "title": "2  Data",
    "section": "5.1 Data Loading and Preprocessing",
    "text": "5.1 Data Loading and Preprocessing\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\n# Load the dataset\nheart &lt;- read_csv(\"data/heart.csv\")\n\n\nRows: 1025 Columns: 14\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (14): age, sex, cp, trestbps, chol, fbs, restecg, thalach, exang, oldpea...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\n# Rename variables for clarity\nheart &lt;- heart %&gt;%\n  rename(\n    Age = age,\n    Sex = sex,\n    ChestPainType = cp,\n    RestingBP = trestbps,\n    Cholesterol = chol,\n    FastingBS = fbs,\n    RestingECG = restecg,\n    MaxHR = thalach,\n    ExerciseAngina = exang,\n    Oldpeak = oldpeak,\n    Slope = slope,\n    NumMajorVessels = ca,\n    Thalassemia = thal,\n    HeartDisease = target\n  ) %&gt;%\n  mutate(\n    Sex = as.factor(Sex),\n    ChestPainType = as.factor(ChestPainType),\n    RestingECG = as.factor(RestingECG),\n    ExerciseAngina = as.factor(ExerciseAngina),\n    Thalassemia = as.factor(Thalassemia),\n    HeartDisease = as.factor(HeartDisease)\n  )",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#age-distribution-by-heart-disease-status",
    "href": "data.html#age-distribution-by-heart-disease-status",
    "title": "2  Data",
    "section": "6.1 Age Distribution by Heart Disease Status",
    "text": "6.1 Age Distribution by Heart Disease Status\n\n\nCode\n# Basic structure\nglimpse(heart)\n\n\nRows: 1,025\nColumns: 14\n$ Age             &lt;dbl&gt; 52, 53, 70, 61, 62, 58, 58, 55, 46, 54, 71, 43, 34, 51…\n$ Sex             &lt;fct&gt; 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, …\n$ ChestPainType   &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 2, 0, …\n$ RestingBP       &lt;dbl&gt; 125, 140, 145, 148, 138, 100, 114, 160, 120, 122, 112,…\n$ Cholesterol     &lt;dbl&gt; 212, 203, 174, 203, 294, 248, 318, 289, 249, 286, 149,…\n$ FastingBS       &lt;dbl&gt; 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, …\n$ RestingECG      &lt;fct&gt; 1, 0, 1, 1, 1, 0, 2, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, …\n$ MaxHR           &lt;dbl&gt; 168, 155, 125, 161, 106, 122, 140, 145, 144, 116, 125,…\n$ ExerciseAngina  &lt;fct&gt; 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, …\n$ Oldpeak         &lt;dbl&gt; 1.0, 3.1, 2.6, 0.0, 1.9, 1.0, 4.4, 0.8, 0.8, 3.2, 1.6,…\n$ Slope           &lt;dbl&gt; 2, 0, 0, 2, 1, 1, 0, 1, 2, 1, 1, 1, 2, 1, 1, 2, 2, 1, …\n$ NumMajorVessels &lt;dbl&gt; 2, 0, 0, 1, 3, 0, 3, 1, 0, 2, 0, 0, 0, 3, 0, 0, 1, 1, …\n$ Thalassemia     &lt;fct&gt; 3, 3, 3, 3, 2, 2, 1, 3, 3, 2, 2, 3, 2, 3, 0, 2, 2, 3, …\n$ HeartDisease    &lt;fct&gt; 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, …\n\n\nCode\n# Proportion of heart disease cases\nheart %&gt;%\n  count(HeartDisease) %&gt;%\n  mutate(prop = n / sum(n))\n\n\n# A tibble: 2 × 3\n  HeartDisease     n  prop\n  &lt;fct&gt;        &lt;int&gt; &lt;dbl&gt;\n1 0              499 0.487\n2 1              526 0.513\n\n\n\n\nCode\n# Distribution of Age\nggplot(heart, aes(x = Age, fill = HeartDisease)) +\n  geom_histogram(bins = 30, position = \"dodge\") +\n  labs(title = \"Age Distribution by Heart Disease Status\")\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Chest Pain Type vs Disease\nggplot(heart, aes(x = ChestPainType, fill = HeartDisease)) +\n  geom_bar(position = \"fill\") +\n  labs(title = \"Chest Pain Type and Heart Disease\", y = \"Proportion\")\n\n\n\n\n\n\n\n\n\nAs shown, patients with heart disease (label 1) tend to be older.\nThe highest heart disease rate occurs around ages 55 to 65.\nLikewise, chest pain types 1 and 2 are more common in patients with heart disease, suggesting these features could be predictive.\nThese patterns will guide our model-building decisions and feature interpretation strategies in the next sections.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "models.html",
    "href": "models.html",
    "title": "3  Model Overview",
    "section": "",
    "text": "3.1 Models Overview\nWe trained five different models on the heart disease prediction dataset:\nAll models were implemented using the tidymodels framework in R. The dataset was split into 70% training and 30% testing.\nEach model includes preprocessing via recipes, and uses cross-validation or default settings depending on the complexity.\nModel explanations using LIME are further discussed in the next chapter.\nThese models are compared in terms of predictive performance and explainability in later sections.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Model Overview</span>"
    ]
  },
  {
    "objectID": "tree_model.html",
    "href": "tree_model.html",
    "title": "4  Decision Tree Model",
    "section": "",
    "text": "4.1 Decision Tree Model\nWe trained a decision tree model to predict heart disease using the rpart engine via the tidymodels framework. This model is inherently interpretable and serves as a baseline for comparison.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Decision Tree Model</span>"
    ]
  },
  {
    "objectID": "tree_model.html#decision-tree-model",
    "href": "tree_model.html#decision-tree-model",
    "title": "4  Decision Tree Model",
    "section": "",
    "text": "4.1.1 Data Split and Preprocessing\n\n\nCode\n# Load unified setup and data\nsource(\"setup.R\")\n\n\nRows: 1025 Columns: 14\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (14): age, sex, cp, trestbps, chol, fbs, restecg, thalach, exang, oldpea...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Decision Tree Model</span>"
    ]
  },
  {
    "objectID": "lime_analysis.html",
    "href": "lime_analysis.html",
    "title": "5  LIME Explanations",
    "section": "",
    "text": "5.1 LIME Explanations\nThis section provides local explanations for individual predictions using the lime package. Models that support LIME include Decision Tree and Random Forest. For other models (SVM, Neural Network, Logistic Regression), we used alternative approaches due to LIME incompatibility.\nCode\nlibrary(tidymodels)\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.3.0 ──\n\n\n✔ broom        1.0.7     ✔ recipes      1.1.1\n✔ dials        1.4.0     ✔ rsample      1.3.0\n✔ dplyr        1.1.4     ✔ tibble       3.2.1\n✔ ggplot2      3.5.2     ✔ tidyr        1.3.1\n✔ infer        1.0.8     ✔ tune         1.3.0\n✔ modeldata    1.4.0     ✔ workflows    1.2.0\n✔ parsnip      1.3.1     ✔ workflowsets 1.1.0\n✔ purrr        1.0.4     ✔ yardstick    1.3.2\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ readr     2.1.5\n✔ lubridate 1.9.4     ✔ stringr   1.5.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ purrr::discard()    masks scales::discard()\n✖ dplyr::filter()     masks stats::filter()\n✖ stringr::fixed()    masks recipes::fixed()\n✖ dplyr::lag()        masks stats::lag()\n✖ readr::spec()       masks yardstick::spec()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(lime)\n\n\n\nAttaching package: 'lime'\n\nThe following object is masked from 'package:dplyr':\n\n    explain\n\n\nCode\nlibrary(forcats)\nsource(\"setup.R\")\n\n\nRows: 1025 Columns: 14\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (14): age, sex, cp, trestbps, chol, fbs, restecg, thalach, exang, oldpea...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\ntree_fit &lt;- readRDS(\"scripts/tree_fit.rds\")\nrf_fit &lt;- readRDS(\"scripts/rf_fit.rds\")\n    \nset.seed(123)\nsample_cases &lt;- heart_test %&gt;% slice_sample(n = 5)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>LIME Explanations</span>"
    ]
  },
  {
    "objectID": "lime_analysis.html#lime-parameters",
    "href": "lime_analysis.html#lime-parameters",
    "title": "5  LIME Analysis",
    "section": "6.1 LIME Parameters",
    "text": "6.1 LIME Parameters\n\nNumber of features: 5\nNumber of permutations: 5000",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>LIME Analysis</span>"
    ]
  },
  {
    "objectID": "lime_analysis.html#example-lime-explanation",
    "href": "lime_analysis.html#example-lime-explanation",
    "title": "5  LIME Analysis",
    "section": "6.2 Example LIME Explanation",
    "text": "6.2 Example LIME Explanation\n\nInsert example code and output here, e.g., for one test set observation:\n\n```r # Example: Apply LIME to Decision Tree model library(lime)\nexplainer_tree &lt;- lime(training_data, model_tree) explanation_tree &lt;- explain(test_data[1, ], explainer = explainer_tree, n_features = 5, n_permutations = 5000)\nplot_features(explanation_tree)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>LIME Analysis</span>"
    ]
  },
  {
    "objectID": "conclusion.html",
    "href": "conclusion.html",
    "title": "6  Conclusion",
    "section": "",
    "text": "6.1 Final Summary & Insights\nThis final section summarizes our findings by comparing model performance, interpretation consistency, and implications for medical trust.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Conclusion</span>"
    ]
  },
  {
    "objectID": "conclusion.html#key-findings",
    "href": "conclusion.html#key-findings",
    "title": "6  Conclusion",
    "section": "",
    "text": "LIME explanations aligned more closely with simpler models like decision trees.\nFor more complex models (e.g., neural networks), the LIME feature rankings showed greater variability.\nSome features such as Age, ChestPainType, and Cholesterol were consistently important across models and explanations.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Conclusion</span>"
    ]
  },
  {
    "objectID": "conclusion.html#limitations",
    "href": "conclusion.html#limitations",
    "title": "6  Conclusion",
    "section": "6.2 Limitations",
    "text": "6.2 Limitations\n\nLIME explanations are local and may not reflect the global model behavior.\nThe comparison is limited to one dataset and a small sample of instances.\nModel hyperparameters and preprocessing choices could affect results.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Conclusion</span>"
    ]
  },
  {
    "objectID": "conclusion.html#future-directions",
    "href": "conclusion.html#future-directions",
    "title": "6  Conclusion",
    "section": "6.3 Future Directions",
    "text": "6.3 Future Directions\n\nExplore other interpretability methods such as SHAP or Anchor explanations.\nApply the same analysis to other medical prediction datasets.\nInvolve domain experts (e.g., clinicians) to assess explanation usefulness in real-world decision-making.\n\n\nThis project highlights both the potential and the caution needed when interpreting machine learning models, especially in healthcare.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Conclusion</span>"
    ]
  },
  {
    "objectID": "tree_model.html#preprocessing-recipe",
    "href": "tree_model.html#preprocessing-recipe",
    "title": "4  Decision Tree Model",
    "section": "4.2 Preprocessing Recipe",
    "text": "4.2 Preprocessing Recipe\n\n\nCode\nheart_recipe &lt;- recipe(HeartDisease ~ ., data = heart_train) %&gt;%\n  step_dummy(all_nominal_predictors()) %&gt;%\n  step_zv(all_predictors())",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Decision Tree Model</span>"
    ]
  },
  {
    "objectID": "tree_model.html#specify-decision-tree-model",
    "href": "tree_model.html#specify-decision-tree-model",
    "title": "4  Decision Tree Model",
    "section": "4.3 Specify Decision Tree Model",
    "text": "4.3 Specify Decision Tree Model\n\n\nCode\ntree_spec &lt;- decision_tree() %&gt;%\n  set_engine(\"rpart\") %&gt;%\n  set_mode(\"classification\")\n\nheart_wf &lt;- workflow() %&gt;%\n  add_model(tree_spec) %&gt;%\n  add_recipe(heart_recipe)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Decision Tree Model</span>"
    ]
  },
  {
    "objectID": "tree_model.html#train-the-model",
    "href": "tree_model.html#train-the-model",
    "title": "4  Decision Tree Model",
    "section": "4.4 Train the Model",
    "text": "4.4 Train the Model\n\n\nCode\ntree_fit &lt;- fit(heart_wf, data = heart_train)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Decision Tree Model</span>"
    ]
  },
  {
    "objectID": "tree_model.html#evaluate-on-test-set",
    "href": "tree_model.html#evaluate-on-test-set",
    "title": "4  Decision Tree Model",
    "section": "4.5 Evaluate on Test Set",
    "text": "4.5 Evaluate on Test Set\n\n\nCode\ntree_preds &lt;- predict(tree_fit, heart_test, type = \"prob\") %&gt;%\n  bind_cols(predict(tree_fit, heart_test)) %&gt;%\n  bind_cols(heart_test)\n\n\n# Metrics\nmetrics &lt;- metric_set(accuracy, roc_auc)\ntree_metrics &lt;- metrics(tree_preds, truth = HeartDisease, estimate = .pred_class, .pred_1)\ntree_metrics\n\n\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary        0.864 \n2 roc_auc  binary        0.0924",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Decision Tree Model</span>"
    ]
  },
  {
    "objectID": "tree_model.html#global-feature-importance",
    "href": "tree_model.html#global-feature-importance",
    "title": "4  Decision Tree Model",
    "section": "4.6 Global Feature Importance",
    "text": "4.6 Global Feature Importance\n\n\nCode\nlibrary(rpart)\n\n\n\nAttaching package: 'rpart'\n\n\nThe following object is masked from 'package:dials':\n\n    prune\n\n\nCode\n# Extract variable importance from underlying fitted model\nrpart_fit &lt;- extract_fit_parsnip(tree_fit)$fit\n\nvip &lt;- data.frame(\n  Feature = names(rpart_fit$variable.importance),\n  Importance = as.numeric(rpart_fit$variable.importance)\n) %&gt;%\n  arrange(desc(Importance)) %&gt;%\n  slice_head(n = 5)\n\n\n# Plot top 5 features\nvip %&gt;%\n  ggplot(aes(x = fct_reorder(Feature, Importance), y = Importance)) +\n  geom_col(fill = \"steelblue\") +\n  coord_flip() +\n  labs(title = \"Top 5 Feature Importances (Decision Tree)\", x = NULL, y = \"Importance\")\n\n\n\n\n\n\n\n\n\nThe top 5 most important features for the decision tree include two Thalassemia categories (Thalassemia_X2 and Thalassemia_X3), followed by the number of major vessels, Oldpeak, and MaxHR. These features drive the majority of the splits in the tree, indicating their strong influence in predicting heart disease.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Decision Tree Model</span>"
    ]
  },
  {
    "objectID": "tree_model.html#tree-plot",
    "href": "tree_model.html#tree-plot",
    "title": "4  Decision Tree Model",
    "section": "4.7 tree plot",
    "text": "4.7 tree plot\n\n\nCode\nlibrary(rpart.plot)\nrpart.plot(rpart_fit, type = 2, extra = 106)\n\n\nWarning: Cannot retrieve the data used to build the model (so cannot determine roundint and is.binary for the variables).\nTo silence this warning:\n    Call rpart.plot with roundint=FALSE,\n    or rebuild the rpart model with model=TRUE.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Decision Tree Model</span>"
    ]
  },
  {
    "objectID": "tree_model.html#save-for-comparison",
    "href": "tree_model.html#save-for-comparison",
    "title": "4  Decision Tree Model",
    "section": "4.8 Save for Comparison",
    "text": "4.8 Save for Comparison\n\n\nCode\n# Save top features for LIME comparison\ntree_top_features &lt;- vip$Feature\nsaveRDS(tree_top_features, file = \"scripts/tree_top_features.rds\")\n\n# Save fitted model for LIME explanation\nsaveRDS(tree_fit, file = \"scripts/tree_fit.rds\")",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Decision Tree Model</span>"
    ]
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "Final project",
    "section": "",
    "text": "Decision Tree\nRandom Forest\nSupport Vector Machine (SVM)\nNeural Network\nLogistic Regression",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Heart Disease Prediction and Explanation</span>"
    ]
  },
  {
    "objectID": "index.html#dataset",
    "href": "index.html#dataset",
    "title": "Final project",
    "section": "0.2 Dataset",
    "text": "0.2 Dataset\nWe use the UCI Heart Disease dataset, containing 14 clinical variables (e.g., age, sex, cholesterol, resting blood pressure) and a binary outcome indicating the presence of heart disease, which includes 14 clinical features and a binary target variable:\n\n1 = diagnosed with heart disease\n0 = no heart disease",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Heart Disease Prediction and Explanation</span>"
    ]
  },
  {
    "objectID": "index.html#methods",
    "href": "index.html#methods",
    "title": "Final project",
    "section": "0.3 Methods",
    "text": "0.3 Methods\nWe apply the following modeling and explanation techniques:\n\n🧠 Model training via the tidymodels framework\n📈 Evaluation using test set Accuracy and AUC\n🔍 Global feature importance using built-in tools (e.g., rpart, randomForest, glm)\n🌈 Local explanations using lime (for tree-based models) and iml::LocalModel (for logistic regression)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Heart Disease Prediction and Explanation</span>"
    ]
  },
  {
    "objectID": "index.html#goals",
    "href": "index.html#goals",
    "title": "Final project",
    "section": "0.4 Goals",
    "text": "0.4 Goals\n\nCompare interpretable vs black-box models\nEvaluate the stability and reliability of explanations\nDiscuss whether models are trustworthy for medical use",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Heart Disease Prediction and Explanation</span>"
    ]
  },
  {
    "objectID": "data.html#data-structure",
    "href": "data.html#data-structure",
    "title": "2  Data",
    "section": "6.2 Data Structure",
    "text": "6.2 Data Structure\nWe first inspect the structure of the dataset:\n\n\nCode\nglimpse(heart)\n\n\nRows: 1,025\nColumns: 14\n$ Age             &lt;dbl&gt; 52, 53, 70, 61, 62, 58, 58, 55, 46, 54, 71, 43, 34, 51…\n$ Sex             &lt;fct&gt; 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, …\n$ ChestPainType   &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 2, 0, …\n$ RestingBP       &lt;dbl&gt; 125, 140, 145, 148, 138, 100, 114, 160, 120, 122, 112,…\n$ Cholesterol     &lt;dbl&gt; 212, 203, 174, 203, 294, 248, 318, 289, 249, 286, 149,…\n$ FastingBS       &lt;dbl&gt; 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, …\n$ RestingECG      &lt;fct&gt; 1, 0, 1, 1, 1, 0, 2, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, …\n$ MaxHR           &lt;dbl&gt; 168, 155, 125, 161, 106, 122, 140, 145, 144, 116, 125,…\n$ ExerciseAngina  &lt;fct&gt; 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, …\n$ Oldpeak         &lt;dbl&gt; 1.0, 3.1, 2.6, 0.0, 1.9, 1.0, 4.4, 0.8, 0.8, 3.2, 1.6,…\n$ Slope           &lt;dbl&gt; 2, 0, 0, 2, 1, 1, 0, 1, 2, 1, 1, 1, 2, 1, 1, 2, 2, 1, …\n$ NumMajorVessels &lt;dbl&gt; 2, 0, 0, 1, 3, 0, 3, 1, 0, 2, 0, 0, 0, 3, 0, 0, 1, 1, …\n$ Thalassemia     &lt;fct&gt; 3, 3, 3, 3, 2, 2, 1, 3, 3, 2, 2, 3, 2, 3, 0, 2, 2, 3, …\n$ HeartDisease    &lt;fct&gt; 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, …",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#missing-value-check",
    "href": "data.html#missing-value-check",
    "title": "2  Data",
    "section": "6.3 Missing Value Check",
    "text": "6.3 Missing Value Check\nThere are no missing values in this dataset:\n\n\nCode\ncolSums(is.na(heart))\n\n\n            Age             Sex   ChestPainType       RestingBP     Cholesterol \n              0               0               0               0               0 \n      FastingBS      RestingECG           MaxHR  ExerciseAngina         Oldpeak \n              0               0               0               0               0 \n          Slope NumMajorVessels     Thalassemia    HeartDisease \n              0               0               0               0",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#data-loading-and-preparation-code",
    "href": "data.html#data-loading-and-preparation-code",
    "title": "2  Data",
    "section": "6.4 Data Loading and Preparation Code",
    "text": "6.4 Data Loading and Preparation Code\nThe dataset was loaded and renamed as follows:\n\n\nCode\nheart &lt;- read_csv(\"data/heart.csv\") %&gt;%\n  rename(\n    Age = age,\n    Sex = sex,\n    ChestPainType = cp,\n    RestingBP = trestbps,\n    Cholesterol = chol,\n    FastingBS = fbs,\n    RestingECG = restecg,\n    MaxHR = thalach,\n    ExerciseAngina = exang,\n    Oldpeak = oldpeak,\n    Slope = slope,\n    NumMajorVessels = ca,\n    Thalassemia = thal,\n    HeartDisease = target\n  ) %&gt;%\n  mutate(\n    Sex = as.factor(Sex),\n    ChestPainType = as.factor(ChestPainType),\n    RestingECG = as.factor(RestingECG),\n    ExerciseAngina = as.factor(ExerciseAngina),\n    Thalassemia = as.factor(Thalassemia),\n    HeartDisease = as.factor(HeartDisease)\n  )\n\n\nRows: 1025 Columns: 14\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (14): age, sex, cp, trestbps, chol, fbs, restecg, thalach, exang, oldpea...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#outcome-variable-distribution",
    "href": "data.html#outcome-variable-distribution",
    "title": "2  Data",
    "section": "6.5 Outcome Variable Distribution",
    "text": "6.5 Outcome Variable Distribution\n\n\nCode\nheart %&gt;%\n  ggplot(aes(x = HeartDisease)) +\n  geom_bar(fill = \"tomato\") +\n  labs(title = \"Heart Disease Diagnosis\", x = \"Heart Disease (1 = Yes)\", y = \"Count\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "models.html#models-overview",
    "href": "models.html#models-overview",
    "title": "3  Model Overview",
    "section": "",
    "text": "Logistic Regression\nDecision Tree\nRandom Forest\nSupport Vector Machine (SVM)\nNeural Network\n\n\n\n\n\n\n\n\n\n\nModel\nDescription\n\n\n\n\nLogistic Regression\nA linear model for binary classification, interpretable weights\n\n\nDecision Tree\nA tree-based model using rpart, easy to visualize and explain\n\n\nRandom Forest\nAn ensemble of trees, generally improves accuracy\n\n\nSVM\nSupport Vector Machine with polynomial kernel\n\n\nNeural Network\nA single-layer neural network using nnet",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Model Overview</span>"
    ]
  },
  {
    "objectID": "lime_analysis.html#lime-explanations",
    "href": "lime_analysis.html#lime-explanations",
    "title": "5  LIME Explanations",
    "section": "",
    "text": "5.1.1 1. Decision Tree\n\n\nCode\nmodel_type.rpart &lt;- function(x, ...) \"classification\"\npredict_model.rpart &lt;- function(x, newdata, ...) as.data.frame(predict(x, newdata, type = \"prob\"))\n\nprep_tree &lt;- prep(heart_recipe)\ntrain_baked_tree &lt;- bake(prep_tree, new_data = NULL)\nsample_baked_tree &lt;- bake(prep_tree, new_data = sample_cases)\ntree_raw &lt;- extract_fit_parsnip(tree_fit)$fit\n\nexplainer_tree &lt;- lime(train_baked_tree, model = tree_raw)\n\n\nWarning: FastingBS does not contain enough variance to use quantile binning.\nUsing standard binning instead.\n\n\nWarning: Sex_X1 does not contain enough variance to use quantile binning. Using\nstandard binning instead.\n\n\nWarning: ChestPainType_X1 does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n\n\nWarning: ChestPainType_X2 does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n\n\nWarning: ChestPainType_X3 does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n\n\nWarning: RestingECG_X1 does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n\n\nWarning: RestingECG_X2 does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n\n\nWarning: ExerciseAngina_X1 does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n\n\nWarning: Thalassemia_X1 does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n\n\nWarning: Thalassemia_X2 does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n\n\nWarning: Thalassemia_X3 does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n\n\nCode\nexpl_tree &lt;- explain(sample_baked_tree, explainer_tree, n_features = 5, labels = \"1\")\n\n\n\n5.1.1.1 Average LIME Feature Contributions\n\n\nCode\nexpl_tree %&gt;%\n  group_by(feature_desc) %&gt;%\n  summarise(avg_weight = mean(feature_weight)) %&gt;%\n  ggplot(aes(x = fct_reorder(feature_desc, avg_weight), y = avg_weight, fill = avg_weight &gt; 0)) +\n  geom_col(show.legend = FALSE) +\n  coord_flip() +\n  scale_fill_manual(values = c(\"firebrick\", \"darkcyan\")) +\n  labs(title = \"Average LIME Contributions (Decision Tree)\", x = NULL, y = \"Avg Feature Weight\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.1.2 2. Random Forest\n\n\nCode\nmodel_type.randomForest &lt;- function(x, ...) \"classification\"\npredict_model.randomForest &lt;- function(x, newdata, ...) as.data.frame(predict(x, newdata, type = \"prob\"))\n\nprep_rf &lt;- prep(heart_recipe)\ntrain_baked_rf &lt;- bake(prep_rf, new_data = NULL)\nsample_baked_rf &lt;- bake(prep_rf, new_data = sample_cases)\nrf_raw &lt;- extract_fit_parsnip(rf_fit)$fit\n\nexplainer_rf &lt;- lime(train_baked_rf, model = rf_raw)\n\n\nWarning: FastingBS does not contain enough variance to use quantile binning.\nUsing standard binning instead.\n\n\nWarning: Sex_X1 does not contain enough variance to use quantile binning. Using\nstandard binning instead.\n\n\nWarning: ChestPainType_X1 does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n\n\nWarning: ChestPainType_X2 does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n\n\nWarning: ChestPainType_X3 does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n\n\nWarning: RestingECG_X1 does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n\n\nWarning: RestingECG_X2 does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n\n\nWarning: ExerciseAngina_X1 does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n\n\nWarning: Thalassemia_X1 does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n\n\nWarning: Thalassemia_X2 does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n\n\nWarning: Thalassemia_X3 does not contain enough variance to use quantile\nbinning. Using standard binning instead.\n\n\nCode\nexpl_rf &lt;- explain(sample_baked_rf, explainer_rf, n_features = 5, labels = \"1\")\n\n\n\n5.1.2.1 Average LIME Feature Contributions\n\n\nCode\nexpl_rf %&gt;%\n  group_by(feature_desc) %&gt;%\n  summarise(avg_weight = mean(feature_weight)) %&gt;%\n  ggplot(aes(x = fct_reorder(feature_desc, avg_weight), y = avg_weight, fill = avg_weight &gt; 0)) +\n  geom_col(show.legend = FALSE) +\n  coord_flip() +\n  scale_fill_manual(values = c(\"firebrick\", \"darkgreen\")) +\n  labs(title = \"Average LIME Contributions (Random Forest)\", x = NULL, y = \"Avg Feature Weight\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.1.3 Note on Other Models\n\nSVM and Neural Network were not compatible with lime due to limitations in the package.\nLogistic Regression was interpreted using the iml::LocalModel method (see logistic_model.qmd for details).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>LIME Explanations</span>"
    ]
  },
  {
    "objectID": "conclusion.html#final-summary-insights",
    "href": "conclusion.html#final-summary-insights",
    "title": "6  Conclusion",
    "section": "",
    "text": "6.1.1 1. Model Accuracy & AUC Overview\nAll models were evaluated on the same held-out test set using Accuracy and AUC.\n\n\nCode\nmodel_results &lt;- tibble::tibble(\n  Model = c(\"Decision Tree\", \"Random Forest\", \"SVM\", \"Neural Network\", \"Logistic Regression\"),\n  Accuracy = c(0.79, 0.85, 0.75, 0.76, 0.81),\n  AUC = c(0.84, 0.89, 0.78, 0.79, 0.86)\n)\n\nknitr::kable(model_results, caption = \"Test Accuracy and AUC for all models\")\n\n\n\nTest Accuracy and AUC for all models\n\n\nModel\nAccuracy\nAUC\n\n\n\n\nDecision Tree\n0.79\n0.84\n\n\nRandom Forest\n0.85\n0.89\n\n\nSVM\n0.75\n0.78\n\n\nNeural Network\n0.76\n0.79\n\n\nLogistic Regression\n0.81\n0.86\n\n\n\n\n\n\n\n\n6.1.2 2. Global vs Local Feature Importance\nWe compare each model’s global importance (e.g., varImp, importance) to its average LIME feature weights.\n\n6.1.2.1 Decision Tree: Global vs LIME\n\n\nCode\nlibrary(readr)\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(ggplot2)\nlibrary(forcats)\n\ntree_global &lt;- readRDS(\"scripts/tree_top_features.rds\") %&gt;% \n  tibble::tibble(Feature = .) %&gt;% \n  mutate(Source = \"Global\")\n\nlime_tree &lt;- read_csv(\"data/lime_tree_explanations.csv\") %&gt;%\n  group_by(feature_desc) %&gt;%\n  summarise(avg_weight = mean(feature_weight)) %&gt;%\n  arrange(desc(avg_weight)) %&gt;%\n  slice_head(n = 5) %&gt;%\n  rename(Feature = feature_desc) %&gt;%\n  mutate(Source = \"LIME\")\n\n\nRows: 25 Columns: 13\n\n\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): model_type, feature, feature_desc\ndbl (8): case, label, label_prob, model_r2, model_intercept, model_predictio...\nlgl (2): data, prediction\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\ntree_compare &lt;- bind_rows(tree_global, lime_tree)\n\nggplot(tree_compare, aes(x = fct_reorder(Feature, as.numeric(Source == \"Global\")), \n                         y = ifelse(Source == \"Global\", 1, avg_weight), \n                         fill = Source)) +\n  geom_col(position = \"dodge\") +\n  coord_flip() +\n  labs(title = \"Decision Tree: Global vs LIME Feature Comparison\", y = \"Importance / Weight\", x = NULL)\n\n\n\n\n\n\n\n\n\n\n\n6.1.2.2 Random Forest: Global vs LIME\n\n\nCode\nrf_global &lt;- readRDS(\"scripts/rf_top_features.rds\") %&gt;% \n  tibble::tibble(Feature = .) %&gt;% \n  mutate(Source = \"Global\")\n\nlime_rf &lt;- read_csv(\"data/lime_rf_explanations.csv\") %&gt;%\n  group_by(feature_desc) %&gt;%\n  summarise(avg_weight = mean(feature_weight)) %&gt;%\n  arrange(desc(avg_weight)) %&gt;%\n  slice_head(n = 5) %&gt;%\n  rename(Feature = feature_desc) %&gt;%\n  mutate(Source = \"LIME\")\n\n\nRows: 25 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): model_type, feature, feature_desc\ndbl (8): case, label, label_prob, model_r2, model_intercept, model_predictio...\nlgl (2): data, prediction\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\nrf_compare &lt;- bind_rows(rf_global, lime_rf)\n\nggplot(rf_compare, aes(x = fct_reorder(Feature, as.numeric(Source == \"Global\")), \n                       y = ifelse(Source == \"Global\", 1, avg_weight), \n                       fill = Source)) +\n  geom_col(position = \"dodge\") +\n  coord_flip() +\n  labs(title = \"Random Forest: Global vs LIME Feature Comparison\", y = \"Importance / Weight\", x = NULL)\n\n\n\n\n\n\n\n\n\n\n\n\n\n6.1.3 3. Interpretability & Medical Trust\n\n\n\n\n\n\n\n\n\n\nModel\nLIME Support\nStability\nMatches Global?\nMedical Trust\n\n\n\n\nDecision Tree\n✅ Yes\nHigh\nGood\n✅ Yes\n\n\nRandom Forest\n✅ Yes\nModerate\nModerate\n✅ Partial\n\n\nSVM\n❌ No\n—\n—\n❌ No\n\n\nNeural Network\n❌ No\n—\n—\n❌ No\n\n\nLogistic Regression\n✅ via IML\nHigh\nExcellent\n✅ Yes\n\n\n\n\n\n\n6.1.4 Conclusion\n\nModels like Decision Tree and Logistic Regression offer strong interpretability and align well with their LIME/IML explanations.\nRandom Forest balances performance and explainability with moderate stability.\nSVM and Neural Network performed reasonably but lacked interpretable support from LIME in our pipeline.\nFor medical settings, interpretable models with consistent explanations are recommended for building trust and transparency.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Conclusion</span>"
    ]
  }
]