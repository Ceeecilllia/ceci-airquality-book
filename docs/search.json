[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Final project",
    "section": "",
    "text": "1 Evaluating LIME Explanations on Heart Disease Prediction Models\nIn healthcare, it is critical to understand how models make predictions — especially when diagnosing heart disease. LIME (Local Interpretable Model-agnostic Explanations) offers human-friendly explanations even for complex models.\nThis project aims to evaluate the reliability of LIME explanations across different model types, including interpretable models such as decision trees and more complex models like neural networks.\nWe will answer the following research questions: - Does LIME provide faithful explanations for interpretable models? - How do LIME’s feature rankings compare across different models? - Can LIME be considered trustworthy for medical prediction tasks?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Evaluating LIME Explanations on Heart Disease Prediction Models</span>"
    ]
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "2  Data",
    "section": "",
    "text": "2.1 Description",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#missing-value-analysis",
    "href": "data.html#missing-value-analysis",
    "title": "2  Data",
    "section": "2.2 Missing value analysis",
    "text": "2.2 Missing value analysis",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  }
]